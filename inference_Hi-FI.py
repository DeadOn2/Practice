import torch
import torchaudio
import numpy as np
import soundfile as sf
import os
from bigvgan import BigVGAN
from speechbrain.inference.speaker import EncoderClassifier
from GigaTestLSTM import Config, TextProcessor, StudentTTS


# ==========================================
# 1. –†—É—á–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –≤–æ–∫–æ–¥–µ—Ä–∞ (–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –ø—É—Ç—å)
# ==========================================
def load_vocoder(device, n_mels=100):
    print(f"‚è≥ –ó–∞–≥—Ä—É–∑–∫–∞ BigVGAN (n_mels={n_mels})...")

    # –£ NVIDIA v2 100-–ø–æ–ª–æ—Å–Ω–∞—è –º–æ–¥–µ–ª—å —Å—É—â–µ—Å—Ç–≤—É–µ—Ç —Ç–æ–ª—å–∫–æ –¥–ª—è 24khz.
    # –≠—Ç–æ –Ω–µ —Å—Ç—Ä–∞—à–Ω–æ, –≤–æ–∫–æ–¥–µ—Ä –ø—Ä–æ—Å—Ç–æ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç –∑–≤—É–∫ –≤ 24000 –ì—Ü.
    if n_mels == 100:
        repo_id = "nvidia/bigvgan_v2_24khz_100band_256x"
    else:
        repo_id = "nvidia/bigvgan_v2_22khz_80band_256x"

    try:
        model = BigVGAN.from_pretrained(repo_id, use_cuda_kernel=False)
        model.remove_weight_norm()
        model.eval().to(device)
        return model
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –≤–æ–∫–æ–¥–µ—Ä–∞: {e}")
        return None


# ==========================================
# 2. –ó–∞–≥—Ä—É–∑–∫–∞ Speaker Encoder –¥–ª—è Zero-Shot
# ==========================================
def load_speaker_encoder(device):
    print("‚è≥ –ó–∞–≥—Ä—É–∑–∫–∞ Speaker Encoder (SpeechBrain)...")
    return EncoderClassifier.from_hparams(
        source="speechbrain/spkrec-ecapa-voxceleb",
        run_opts={"device": device}
    )


def get_spk_emb(audio_path, encoder, device):
    signal, fs = torchaudio.load(audio_path)
    if fs != 16000:
        signal = torchaudio.transforms.Resample(orig_freq=fs, new_freq=16000)(signal)
    if signal.shape[0] > 1:
        signal = torch.mean(signal, dim=0, keepdim=True)

    with torch.no_grad():
        emb = encoder.encode_batch(signal.to(device))
        return emb.squeeze(1)  # [1, 192]


# ==========================================
# 3. –§—É–Ω–∫—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
# ==========================================
def generate_audio_bigvgan(student_model, vocoder, spk_encoder, text, ref_audio, cfg, processor,
                           output_path="output_bigvgan.wav"):
    student_model.eval()
    device = "cpu"

    # --- –≠–¢–ê–ü 1: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –≤—Ö–æ–¥–∞ ---
    tokens = torch.tensor([processor.encode(text)], dtype=torch.long).to(device)
    lens = torch.tensor([tokens.size(1)]).to(device)

    # –ö–ª–æ–Ω–∏—Ä—É–µ–º –≥–æ–ª–æ—Å (Zero-Shot)
    spk_emb = get_spk_emb(ref_audio, spk_encoder, device)

    # --- –≠–¢–ê–ü 2: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –º–µ–ª–∞ –°—Ç—É–¥–µ–Ω—Ç–æ–º ---
    print(f"üé§ –°—Ç—É–¥–µ–Ω—Ç –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –º–µ–ª-—Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º—É...")
    with torch.no_grad():
        # –í–ê–ñ–ù–û: –ø–µ—Ä–µ–¥–∞–µ–º speaker_embs, —Ç–∞–∫ –∫–∞–∫ –º—ã –≤ —Ä–µ–∂–∏–º–µ Zero-Shot
        mel_output, stop_tokens, _ = student_model(tokens, lens, speaker_embs=spk_emb)

    if mel_output.shape[1] == 0:
        print("‚ùå –û—à–∏–±–∫–∞: –†–∞–Ω–Ω—è—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ (–º–æ–¥–µ–ª—å –≤—ã–¥–∞–ª–∞ –ø—É—Å—Ç–æ–π –º–µ–ª).")
        return

    mel = mel_output.squeeze(0).cpu()

    # --- –≠–¢–ê–ü 3: –î–µ–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è (–ø–æ–¥ BigVGAN) ---
    # –ü–µ—Ä–µ–≤–æ–¥ –∏–∑ 0..1 –æ–±—Ä–∞—Ç–Ω–æ –≤ –¥–µ—Ü–∏–±–µ–ª—ã
    mel_db = (mel * 80) - 80

    # –ü–µ—Ä–µ–≤–æ–¥ dB –≤ –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫—É—é –∞–º–ø–ª–∏—Ç—É–¥—É (ln), –∫–æ—Ç–æ—Ä—É—é –∂–¥–µ—Ç BigVGAN
    mel_log = mel_db * 0.11512925

    # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –≤–∏–¥—É [Batch, Channels, Time]
    mel_input = mel_log.T.unsqueeze(0).to(device)

    # --- –≠–¢–ê–ü 4: –°–∏–Ω—Ç–µ–∑ –∑–≤—É–∫–∞ ---
    print(f"üîä BigVGAN —Å–∏–Ω—Ç–µ–∑–∏—Ä—É–µ—Ç –≤–æ–ª–Ω—É –∏–∑ {mel_input.shape[2]} –∫–∞–¥—Ä–æ–≤...")
    with torch.no_grad():
        wav = vocoder(mel_input)
        wav = wav.squeeze().cpu().numpy()

    # --- –≠–¢–ê–ü 5: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ ---
    if np.max(np.abs(wav)) > 0:
        wav = wav / np.max(np.abs(wav))

    # –í–ê–ñ–ù–û: –ú–æ–¥–µ–ª—å 100band –æ—Ç NVIDIA —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ 24000 –ì—Ü
    target_sr = 24000 if cfg.n_mels == 100 else 22050
    sf.write(output_path, wav, target_sr)
    print(f"‚ú® –ü–æ–±–µ–¥–∞! –§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_path}")


# ==========================================
# Main
# ==========================================
if __name__ == "__main__":
    cfg = Config()
    cfg.n_mels = 100  # –£–±–µ–¥–∏—Å—å, —á—Ç–æ —Ç—É—Ç 100
    tp = TextProcessor(cfg.RUS_ALPHABET)

    student = StudentTTS(cfg).to("cpu")
    ckpt_path = "checp_old/student_step_16750.pth"

    if os.path.exists(ckpt_path):
        ckpt = torch.load(ckpt_path, map_location="cpu")
        student.load_state_dict(ckpt['model_state_dict'])
        print(f"‚úÖ –°—Ç—É–¥–µ–Ω—Ç –∑–∞–≥—Ä—É–∂–µ–Ω (Step: 17250)")

        vocoder = load_vocoder("cpu", n_mels=cfg.n_mels)
        spk_encoder = load_speaker_encoder("cpu")

        if vocoder is not None:
            text = "–ü—Ä–∏–≤–µ—Ç! –Ø –∏—Å–ø–æ–ª—å–∑—É—é –≤–æ–∫–æ–¥–µ—Ä –ë–∏–≥ –í–∏ –ì–∞–Ω –≤–µ—Ä—Å–∏–∏ –¥–≤–∞ –¥–ª—è —á–∏—Å—Ç–æ–≥–æ –∑–≤—É—á–∞–Ω–∏—è."
            # –ó–∞–º–µ–Ω–∏ –Ω–∞ –ø—É—Ç—å –∫ —Å–≤–æ–µ–º—É —Ä–µ–∞–ª—å–Ω–æ–º—É —Ñ–∞–π–ª—É –¥–ª—è –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è!
            reference = "samples/audio_2026-02-16_01-29-54.wav"

            if os.path.exists(reference):
                generate_audio_bigvgan(student, vocoder, spk_encoder, text, reference, cfg, tp)
            else:
                print(f"‚ö†Ô∏è –§–∞–π–ª —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–∞ {reference} –Ω–µ –Ω–∞–π–¥–µ–Ω.")
    else:
        print(f"‚ùå –ß–µ–∫–ø–æ–∏–Ω—Ç {ckpt_path} –Ω–µ –Ω–∞–π–¥–µ–Ω.")